{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application works by reading a video file using cv2.VideoCapture() frame by frame. Each frame is then de-noised by applying cv2.GaussianBlur(). Which is a low-pass filter that removes high-frequency components (e.g. noise, edges) from the image. This is a common practice in image processing to prepare the image for further processing.\n",
    "\n",
    "Then, each frame is processed by an instance of a background subtractor initialized by cv2.createBackgroundSubtractorKNN() method. I've explored existing background subtraction techniques[1] and found KNN more suitable for this case because it produces less noise and preserves the shape of the objects for a longer period of time. This is important because moving objects may stay in the same place for a few frames and we don't want to lose them.\n",
    "\n",
    "The results of the apply() method are the foreground mask. The foreground mask is then tresholded using cv2.threshold() method to remove the noise and produce a binary image. The binary image is then processed by cv2.morphologyEx() method to fill the holes in the foreground objects. The resulting image is then processed by cv2.findContours() method to find the contours of the foreground objects. The contours are then filtered by certain hard-coded minimum area defined by a MIN_CONTOUR_AREA constant. Then we remove the contours that are in the top half of the image because we are only interested in the cars on the Main Street. The remaining contours are then processed by cv2.convexHull() method because cars morphologically are convex objects. The resulting contours are then enclosed by a rectangle using cv2.boundingRect() method. The resulting rectangles are then drawn on the original frame using cv2.rectangle() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/dima/miniconda3/lib/python3.11/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy in /Users/dima/miniconda3/lib/python3.11/site-packages (1.25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OpenCV library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The higher the value, the bigger a moving object should be to be detected\n",
    "MIN_CONTOUR_AREA = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the sample video file:\n",
    "video = cv2.VideoCapture(\"Traffic_Laramie_1.mp4\")\n",
    "\n",
    "# Ensure that the file was opened correctly:\n",
    "assert video.isOpened(), \"Can't open the video file\"\n",
    "\n",
    "# Initialize an instance of [Gaussian Mixture-based Background/Foreground Segmentation Algorithm](https://docs.opencv.org/3.4/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html):\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(detectShadows=False, history=10000, dist2Threshold=900)\n",
    "\n",
    "cv2.namedWindow(\"Cam\")\n",
    "\n",
    "# Read the video frame by frame:\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Check for the last frame\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # blur the frame to remove noise\n",
    "    blured_frame = cv2.GaussianBlur(frame, (5,5), 0)\n",
    "\n",
    "    # Apply the background subtraction algorithm:\n",
    "    fg_mask = bg_subtractor.apply(blured_frame)\n",
    "\n",
    "    # Threshold the foreground mask to remove the shadows:\n",
    "    _, fg_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply morphological operations to remove corruptions:\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Find the contours of the detected objects:\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter out the contours that are too small to be a car:\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > MIN_CONTOUR_AREA]\n",
    "\n",
    "    # Filter out the contours that in the upper half of the frame,\n",
    "    # because we are only interested in the cars that are running along the Main Street:\n",
    "    contours = [c for c in contours if cv2.boundingRect(c)[1] > frame.shape[0] / 2]\n",
    "\n",
    "    # Convex hull to get clean contours without holes:\n",
    "    contours = [cv2.convexHull(c) for c in contours]\n",
    "\n",
    "    # Draw the contours for debugging purposes:\n",
    "    # cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Prepare bounding boxes for the tracker\n",
    "    bboxes = []\n",
    "\n",
    "    # Get the bounding boxes of the contours:\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "        bboxes.append([x, y, x+w, y+h])\n",
    "\n",
    "    for [x,y, x2,y2] in bboxes:\n",
    "        # Draw the bounding box around the detected object\n",
    "        cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow(\"Cam\", frame)\n",
    "\n",
    "    # Press \"q\" to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyWindow(\"Cam\")\n",
    "        cv2.waitKey(1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
